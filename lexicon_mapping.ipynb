{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "physical-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class LexiconMapper:\n",
    "    \n",
    "    \n",
    "    def remove_repeatings(self, word):\n",
    "        prev_char = ''\n",
    "        new_word = []\n",
    "        for char in word:\n",
    "            if char == prev_char:\n",
    "                continue\n",
    "            new_word.append(char)\n",
    "            prev_char = char\n",
    "        return ''.join(new_word)\n",
    "    \n",
    "    def map_tweets(self, tweets, dict_lex, value_index, convert_float):\n",
    "        \n",
    "\n",
    "        mapped_tweets=[]\n",
    "        for sentence in tweets.text:\n",
    "            mapped_sentence=[]\n",
    "            for word in sentence.split():\n",
    "                new_word = self.remove_repeatings(word)\n",
    "                \n",
    "                if word in dict_lex.keys():\n",
    "                    if convert_float:\n",
    "                        mapped_sentence.append(float(dict_lex[word][value_index]))\n",
    "                    else:\n",
    "                        mapped_sentence.append(dict_lex[word][value_index])\n",
    "                        \n",
    "                elif new_word in dict_lex.keys():\n",
    "                    if convert_float:\n",
    "                        mapped_sentence.append(float(dict_lex[new_word][value_index]))\n",
    "                    else:\n",
    "                        mapped_sentence.append(dict_lex[new_word][value_index])\n",
    "                else:\n",
    "                    mapped_sentence.append(-1)\n",
    "            mapped_tweets.append(mapped_sentence)\n",
    "        \n",
    "        tweets['mapped'] = mapped_tweets\n",
    "        return tweets\n",
    "    \n",
    "    \n",
    "    def get_sample(self, dataframe, attribute, value, size):\n",
    "        \n",
    "        return dataframe[attribute == value].sample(size, random_state=23)\n",
    "    \n",
    "    \n",
    "    def add_labels(self, tweets, index, low_bound, high_bound):\n",
    "        \n",
    "        classes = []\n",
    "        for i in tweets.values[:,index]:\n",
    "            if i > high_bound:\n",
    "                classes.append(\"high\")\n",
    "            elif i > low_bound and i <= high_bound:\n",
    "                classes.append(\"medium\")\n",
    "            elif i < low_bound and i > 0:\n",
    "                classes.append(\"low\")\n",
    "            else:\n",
    "                classes.append(\"none\")\n",
    "        \n",
    "        tweets['values'] = classes\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    \n",
    "    \n",
    "    def filter_tweets(self, tweets, filter_value, percent):\n",
    "        filtered = []\n",
    "        \n",
    "        for tweet in tweets.mapped:\n",
    "            t_len = len(tweet)\n",
    "            \n",
    "            not_found = 0\n",
    "            for el in tweet:\n",
    "                if int(el) == -1:\n",
    "                    not_found = not_found + 1\n",
    "            if float(not_found/t_len) < float(percent):\n",
    "                filtered.append(True)\n",
    "            else:\n",
    "                filtered.append(False)\n",
    "                \n",
    "                \n",
    "        tweets['filtered'] = filtered\n",
    "        \n",
    "        return tweets\n",
    "                        \n",
    "    \n",
    "    def get_maximum(self, mapped_tweets):\n",
    "        maximums = []\n",
    "        for tweet in mapped_tweets:\n",
    "            maximum = max(tweet)\n",
    "            maximums.append(maximum)\n",
    "            \n",
    "        return maximums\n",
    "            \n",
    "        \n",
    "    def get_average(self, mapped_tweets):\n",
    "        averages = []\n",
    "        for tweet in mapped_tweets:\n",
    "            filtered_not_founds = [num for num in tweet if num != -1]\n",
    "            average = round(sum(filtered_not_founds)/len(filtered_not_founds), 2)\n",
    "            averages.append(average)\n",
    "            \n",
    "        return averages\n",
    "    \n",
    "\n",
    "class Analyzer:\n",
    "    \n",
    "    def get_length_statistics(self, tweets):\n",
    "        \n",
    "        lengths = [len(tweet) for tweet in tweets.mapped]\n",
    "        return Counter(lengths)\n",
    "    \n",
    "    \n",
    "    def labels_distribution(self, aggregate, low_bound, high_bound):\n",
    "        \n",
    "        aggregate = Counter(aggregate)\n",
    "        low = 0\n",
    "        high = 0\n",
    "        med = 0\n",
    "        for i in aggregate.keys():\n",
    "            if i < low_bound:\n",
    "                low = low + aggregate[i]\n",
    "            if i > high_bound:\n",
    "                high = high + aggregate[i]\n",
    "            else:\n",
    "                med = med + aggregate[i]\n",
    "                \n",
    "        return low, med, high\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-forward",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
